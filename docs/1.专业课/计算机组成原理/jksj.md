
现代计算机都是以冯诺依曼结构为基础设计的

冯诺依曼结构五部分:运算器，控制器，存储器，输入设备，输出设备

CPU主频，可以简单地理解为，1秒内可以执行多少个简单指令

CPU时钟周期是：1/主频

程序响应时间＝指令数 * CPI * 时钟周期

功耗？

计算机最终只能执行01这种机器指令，因为CPU本质上是由各种开关组成的逻辑电路组合，只有开和关两种状态，所有的高级语言最终执行的时候也都是以机器指令来执行的

PC寄存器存储下一条要执行的指令的地址；指令寄存器存储当前正在执行的指令内容；

if/else和for/while，在汇编的层面都是通过jmp相关指令来完成跳转的，其实就是修改下PC寄存器的值

把一个实际调用的函数产生的指令，直接插入到调用的位置，来替换对应的函数调用指令。这是一个常见的编译器进行自动优化的场景，我们通常叫函数内联。
内联带来的优化是，CPU需要执行的指令数变少了，根据地址跳转的过程不需要了，压栈和出栈的过程也不 用了。
不过内联并不是没有代价，内联意味着，我们把可以复用的程序指令在调用它的地方完全展开了。如果一个函数在很多地方都被调用了，那么就会展开很多次，整个程序占用的空间就会变大了。

函数调用过程模糊？

![](https://fanchaoo-notebook.oss-cn-beijing.aliyuncs.com/img/WX20191009-105327@2x.png)

ELF（Execuatable and Linkable File Format）

PE（Portable Executable Format）

如果我们有一个可以能够解析PE格式的装载器，我们就有可能在Linux下运行Windows程序了。这样的程序真的存在吗？没错，Linux下著名的开源项目Wine，就是通过兼容PE格式的装载器，使得我们能直接在Linux下运行Windows程序的。而现在微软的Windows里面也提供了WSL，也就是Windows Subsystem for Linux，可以解析和加载ELF格式的文件。不过很多程序还依赖各种操作系统本身提供的动态链接库，系统调用等等，需要wine提供对应的实现，兼容格式只是万里长征第一步。


"解释执行"的详细过程？

物理内存，虚拟内存？JVM申请的是物理内存吧？

动态链接的过程中，我们想要“链接”的，不是存储在硬盘上的目标文件代码，而是加载到内存中的共享库（Shared Libraries）


数值和字符，在计算机内都需要用二进制形式来表示

电报是现代计算机的一个最简单的原型。它和我们现在使用的现代计算机有很多相似之处。我们通过电路的“开”和“关”，来表示“1”和“0”。就像晶体管在不同的情况下，表现为导电的“1”和绝缘的“0”的状态。

我们可以通过设置不同的线路和开关状态，实现更多不同的信号表示和处理方式，这些线路的连接方式其实就是我们在数字电路中所说的门电路。而这些门电路，也是我们创建CPU和内存的基本逻辑单元。我们的各种对于计算机二进制的“0”和“1”的操作，其实都会由这些门电路来执行。


这些基本的门电路，是我们计算机硬件端的最基本的“积木”，就好像乐高积木里面最简单的小方块。看似不起眼，但是把它们组合起来，最终可以搭出一个星球大战里面千年隼这样的大玩意儿。我们今天包含十亿级别晶体管的现代CPU，都是由这样一个一个的门电路组合而成的。


要表示一个8位数的整数，简单地用8个bit，也就是8个电路开关就好了


通过一个异或门计算出个位，通过一个与门计算出是否进位，我们就通过电路算出了一个一位数的加法。于是，我们把两个门电路打包，给它取一个名字，就叫作半加器（Half Adder，单个比特加法）


在硬件层面，我们通过门电路、半加器、全加器一层层搭出了加法器这样的功能组件。我们把这些用来做算术逻辑计算的组件叫作ALU，也就是算术逻辑单元。当进一步打造强大的CPU时，我们不会再去关注最细颗粒的门电路，只需要把门电路组合而成的ALU，当成一个能够完成基础计算的黑盒子就可以了。


无论是这里把对应的门电路逻辑进行完全展开以减少门延迟，还是上面的乘法通过并行计算多个位的乘法，都是把我们完成一个计算的电路变复杂了。而电路变复杂了，也就意味着晶体管变多了。我们通过更多的晶体管，就可以拿到更低的门延迟，以及用更少的时钟周期完成一个计算指令。

通过精巧地设计电路，用较少的门电路和寄存器，就能够计算完成乘法这样相对复杂的运算。是用更少更简单的电路，但是需要更长的门延迟和时钟周期；还是用更复杂的电路，但是更短的门延迟和时钟周期来计算一个复杂的指令，这之间的权衡，其实就是计算机体系结构中RISC和CISC的经典历史路线之争。

![二进制乘法计算过程](https://fanchaoo-notebook.oss-cn-beijing.aliyuncs.com/img/WechatIMG178.png)


回到浮点数的加法过程，你会发现，其中指数位较小的数，需要在有效位进行左移，在左移的过程中，最右侧的有效位就被丢弃掉了。这会导致对应的指数位较小的数，在加法发生之前，就丢失精度。两个相加数的指数位差的越大，位移的位数越大，可能丢失的精度也就越大。当然，也有可能你的运气非常好，右移丢失的有效位都是0。这种情况下，对应的加法虽然丢失了需要加的数字的精度，但是因为对应的值都是0，实际的加法的数值结果不会有精度损失。

32位浮点数的有效位长度一共只有23位，如果两个数的指数位差出23位，较小的数右移24位之后，所有的有效位就都丢失了。这也就意味着，虽然浮点数可以表示上到$3.40×10^{38}$，下到$1.17×10^{-38}$这样的数值范围。但是在实际计算的时候，只要两个数，差出$2^{24}$，也就是差不多1600万倍，那这两个数相加之后，结果完全不会变化。

在32位浮点数中，符号位占1位，尾数占23位，阶数占8位。

在64位浮点数中，符号位占1位，尾数占52位，阶数占11位。


ALU的功能就是在特定的输入下，根据下面的组合电路的逻辑，生成特定的输出，实际就是一个没有状态的，根据输入计算输出结果的第一个 电路。运算器里的ALU和各种组合逻辑电路，可以认为是一个固定功能的电路。

我们看似写了各种复杂的高级程序进行各种函数调用、条件跳转。其实只是修改PC寄存器里面的地址。PC 寄存器里面的地址一修改，计算机就可以加载一条指令新指令，往下运行。



CPU运转需要的4种基本电路。它们分别是，ALU这样的组合逻辑电路、用来存储数据的锁存器和D触发器电路、用来实现 PC寄存器的计数器电路，以及用来解码和寻址的译码器电路。



我们可以通过自动计数器的电路，来实现一个PC寄存器，不断生成下一条要执行的计算机指令的内存地 址。然后通过译码器，从内存里面读出对应的指令，写入到D触发器实现的指令寄存器中。再通过另外一个 译码器，把它解析成我们需要执行的指令和操作数的地址。这些电路，组成了我们计算机五大组成部分里面 的控制器。
我们把opcode和对应的操作数，发送给ALU进行计算，得到计算结果，再写回到寄存器以及内存里面来， 这个就是我们计算机五大组成部分里面的运算器。
我们的时钟信号，则提供了协调这样一条条指令的执行时间和先后顺序的机制。同样的，这也带来了一个挑
战，那就是单指令周期处理器去执行一条指令的时间太长了。而这个挑战，也是我们接下来的几讲里要解答
的问题。

一条CPU指令的执行，是由“取得指令(Fetch)-指令译码(Decode)- 执行指令(Execute) ”这样三个步骤组成的


如果某一个操作步骤的时间太长，我们就可以考虑把这个步骤，拆分成更多的步骤，让所有步骤需要执行的 时间尽量都差不多长。这样，也就可以解决我们在单指令周期处理器中遇到的，性能瓶颈来自于最复杂的指 令的问题。像我们现代的ARM或者Intel的CPU，流水线级数都已经到了14级。

我们用来同步时钟周期的，不再是指令级别的，而是流水线阶段级别的。每一级流水线对应的输出，都要放 到流水线寄存器(Pipeline Register)里面，然后在下一个时钟周期，交给下一个流水线级去处理。所以， 每增加一级的流水线，就要多一级写入到流水线寄存器的操作。

单纯地增加流水线级数，不仅不能提升性能，反而会有 更多的overhead的开销。所以，设计合理的流水线级数也是现代CPU中非常重要的一点。

要知道，增加流水线深度，在同主频下，其实是降低了CPU的性能。因为一个Pipeline Stage，就需要一个 时钟周期。那么我们把任务拆分成31个阶段，就需要31个时钟周期才能完成一个任务;而把任务拆分成11 个阶段，就只需要11个时钟周期就能完成任务。在这种情况下，31个Stage的3GHz主频的CPU，其实和11个 Stage的1GHz主频的CPU，性能是差不多的。事实上，因为每个Stage都需要有对应的Pipeline寄存器的开 销，这个时候，更深的流水线性能可能还会更差一些。


流水线技术并不能缩短单条指令的响应时间这个性能指标，但是可以增加在运行很多条 指令时候的吞吐率。

如果我们有20级流水线，意味着我们要确保这20条指令之间没有依赖关系。这个挑战一下子就变大 了很多。毕竟我们平时撰写程序，通常前后的代码都是有一定的依赖关系的，几十条没有依赖关系的指令可 不好找。这也是为什么，超长流水线的执行效率发而降低了的一个重要原因。
